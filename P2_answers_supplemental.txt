Jason Chen and Gerry Lin

1.1) For the ReflexAgent implementation, I used Manhattan distance to calculate the distance to the closest food and ghost.
Then I used these values to help the agent determine its next action.

1.2) The evaluation function that I used was "20 / (foodDistance + 1) - 5 / (scaredGhostDistance + 1)" and . I used 20 for food 
distance so the food that are closest will have higher priority and it produced results that are greater than 1200. I used 5
for the distance from a ghost to prevent Pacman from getting eaten by a ghost. If I used a higher number like 10, sometimes
Pacman will be too scared of the ghost and not progress. For the food distance, if 20 was lower, Pacman would also sometimes 
stay in place to avoid the ghost.

2.1) My method has max_value method that determines the action of the max agent. It calls the min_value method to determine
the score of the next depth to decide its action. This works because it finds the highest score of the successors to determine
its next action. 
In the min_value method, it finds the action that will result in a lower score. When it is the last min agent, it will call the 
max_value method to find the score of the next depth to determine its action because next agent will be the max agent. The min_value
method works because after getting all the scores, it will find the action that results in the lowest score for the max agent.

3.1) The AlphaBetaAgent minimax values should be identical to MinimaxAgent values because the AlphaBetaAgent is the basically the 
same as the MinimaxAgent except that it prunes some of the subtrees.

3.2) For the method, if there is a tie, the function will choose the first explored action.  


